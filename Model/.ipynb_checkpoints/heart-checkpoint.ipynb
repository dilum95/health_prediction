{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28129be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36d387e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0              6      148             72             35        0  33.6   \n",
      "1              1       85             66             29        0  26.6   \n",
      "2              8      183             64              0        0  23.3   \n",
      "3              1       89             66             23       94  28.1   \n",
      "4              0      137             40             35      168  43.1   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "763           10      101             76             48      180  32.9   \n",
      "764            2      122             70             27        0  36.8   \n",
      "765            5      121             72             23      112  26.2   \n",
      "766            1      126             60              0        0  30.1   \n",
      "767            1       93             70             31        0  30.4   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                       0.627   50        1  \n",
      "1                       0.351   31        0  \n",
      "2                       0.672   32        1  \n",
      "3                       0.167   21        0  \n",
      "4                       2.288   33        1  \n",
      "..                        ...  ...      ...  \n",
      "763                     0.171   63        0  \n",
      "764                     0.340   27        0  \n",
      "765                     0.245   30        0  \n",
      "766                     0.349   47        1  \n",
      "767                     0.315   23        0  \n",
      "\n",
      "[768 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data_2 = pd.read_csv(r'diabetes.csv')\n",
    "print(data_2)\n",
    "\n",
    "data_2=data_2.fillna(0) # fill NAs  with 0 \n",
    "\n",
    "X = data_2.drop(['Outcome'], axis=1)\n",
    "y = data_2.Outcome\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "876b6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.24390321424072173\n",
      "KNeighborsClassifier(n_neighbors=6)\n",
      "{'n_neighbors': 6, 'weights': 'uniform'}\n",
      "[[147  21]\n",
      " [ 41  45]]\n",
      "-0.08997785160575877\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Select an algorithm\n",
    "algorithm = KNeighborsClassifier()\n",
    "seed = 13\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "# Define our candidate hyperparameters\n",
    "hp_candidates = [{'n_neighbors': [2,3,4,5,6], 'weights': ['uniform','distance']}]\n",
    "# Search for best hyperparameters\n",
    "grid = GridSearchCV(estimator=algorithm, param_grid=hp_candidates, cv=kfold, scoring='r2')\n",
    "knn =grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the results\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_) \n",
    "# Create 3 folds\n",
    "\n",
    "knn_predictions = knn.predict(X_test) \n",
    "cm = confusion_matrix(y_test, knn_predictions)\n",
    "print(cm)\n",
    "classification_report(y_test, knn_predictions)\n",
    "# accuracy on X_test\n",
    "accuracy = knn.score(X_test, y_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d84bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7440944881889764\n",
      "[[138  30]\n",
      " [ 35  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81       168\n",
      "           1       0.63      0.59      0.61        86\n",
      "\n",
      "    accuracy                           0.74       254\n",
      "   macro avg       0.71      0.71      0.71       254\n",
      "weighted avg       0.74      0.74      0.74       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Na√Øve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb_clf=GaussianNB()\n",
    "parameters = {\n",
    "    'var_smoothing': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]\n",
    "}\n",
    "clf = GridSearchCV(gnb_clf, parameters, cv=5)\n",
    "gnb=clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "gnb_predictions = gnb.predict(X_test)\n",
    "  \n",
    "# accuracy on X_test\n",
    "accuracy = gnb.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, gnb_predictions)\n",
    "print(cm)\n",
    "creport=classification_report(y_test, gnb_predictions)\n",
    "print(creport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaee3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7913385826771654\n",
      "[[148  20]\n",
      " [ 33  53]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       168\n",
      "           1       0.73      0.62      0.67        86\n",
      "\n",
      "    accuracy                           0.79       254\n",
      "   macro avg       0.77      0.75      0.76       254\n",
      "weighted avg       0.79      0.79      0.79       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=1, cv=cv)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "logreg=model.fit(X_train, y_train)\n",
    "log_predictions = grid_result.predict(X_test)\n",
    "\n",
    "# accuracy on X_test\n",
    "accuracy = grid_result.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "  \n",
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, log_predictions)\n",
    "print(cm)\n",
    "clas_report=classification_report(y_test, log_predictions)\n",
    "print(clas_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720fb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_heart','wb') as file:\n",
    "    pickle.dump(grid_result,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28f9594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "625            4       90             88             47       54  37.7   \n",
      "493            4      125             70             18      122  28.9   \n",
      "263            3      142             80             15        0  32.4   \n",
      "411            1      112             72             30      176  34.4   \n",
      "87             2      100             68             25       71  38.5   \n",
      "..           ...      ...            ...            ...      ...   ...   \n",
      "47             2       71             70             27        0  28.0   \n",
      "129            0      105             84              0        0  27.9   \n",
      "389            3      100             68             23       81  31.6   \n",
      "14             5      166             72             19      175  25.8   \n",
      "84             5      137            108              0        0  48.8   \n",
      "\n",
      "     DiabetesPedigreeFunction  Age  \n",
      "625                     0.362   29  \n",
      "493                     1.144   45  \n",
      "263                     0.200   63  \n",
      "411                     0.528   25  \n",
      "87                      0.324   26  \n",
      "..                        ...  ...  \n",
      "47                      0.586   22  \n",
      "129                     0.741   62  \n",
      "389                     0.949   28  \n",
      "14                      0.587   51  \n",
      "84                      0.227   37  \n",
      "\n",
      "[254 rows x 8 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 4.    90.    88.    47.    54.    37.5    0.365 29.   ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14030/236776587.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m47\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m54\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m37.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.365\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mavailable_if\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator_has\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/linear_model/logistic_path.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdaal4py_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'computeClassLabels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpredict_log_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/daal4py/sklearn/linear_model/logistic_path.py\u001b[0m in \u001b[0;36mdaal4py_predict\u001b[0;34m(self, X, resultsToEvaluate)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdaal4py_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresultsToEvaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mfptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFPType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    770\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 4.    90.    88.    47.    54.    37.5    0.365 29.   ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "with open('model_heart','rb') as file:\n",
    "    mp = pickle.load(file)\n",
    "\n",
    "print(X_test)    \n",
    "pre=mp.predict([4,90,88,47,54,37.5,0.365,29])\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df983c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model= DecisionTreeClassifier()\n",
    "parameters={\n",
    "            \"max_depth\" : [7,9,11,12,15],\n",
    "           \"min_samples_leaf\":[50,10,100],\n",
    "           \"min_weight_fraction_leaf\":[0.0001,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_leaf_nodes\":[None,1,20,30,40,50,60,70,80,90] }\n",
    "\n",
    "tuning_model=GridSearchCV(estimator=model,param_grid=parameters,cv=3,verbose=3)\n",
    "\n",
    "dtree_model =tuning_model.fit(X_train, y_train)\n",
    "\n",
    "#dtree_model = DecisionTreeClassifier(max_depth = 15).fit(X_train, y_train)\n",
    "dtree_predictions = dtree_model.predict(X_test)\n",
    "accuracy = dtree_model.score(X_test, y_test)\n",
    "print(accuracy)  \n",
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, dtree_predictions)\n",
    "print(cm)\n",
    "\n",
    "cls_report=classification_report(y_test, dtree_predictions)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27324350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Device support is limited in daal4py patching. Use Intel(R) Extension for Scikit-learn* for full experience.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "with open('model_heart','rb') as file:\n",
    "    mp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a32b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67, 0, 3, 115, 564, 0, 2, 160]\n",
      "[1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dilum/.local/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test_new = [0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "print(X_test_new)\n",
    "datanew=pd.DataFrame(X_test_new).transpose()\n",
    "pre=mp.predict(datanew)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973081c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
